{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPyyp6/q1AGG1ve9brn+HuB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rishantmallick/conference-predictor/blob/main/KDSH_conference_selector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2apBUXQ2Bq7"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install langgraph\n",
        "!pip install  openai\n",
        "!pip install PyPDF2\n",
        "!pip install scikit-learn\n",
        "!pip install -U langchain-tavily\n",
        "!pip install textstat\n",
        "!pip install -U langchain-community\n",
        "!pip install arxiv --upgrade\n",
        "!pip install Pydantic\n",
        "!pip install langchain_core\n",
        "!pip install langchain_openai\n",
        "!pip install serpapi\n",
        "!pip install google-search-results\n",
        "!pip install scikit-learn\n",
        "!pip install gensim\n",
        "!pip install nltk\n",
        "!pip install pypdf\n",
        "!pip install numpy\n",
        "!pip install --force-reinstall --no-cache-dir numpy gensim\n",
        "!pip install faiss-cpu\n",
        "!pip install tiktoken\n",
        "!pip install langchain_google_vertexai\n",
        "!pip install google-generativeai\n",
        "!pip install langchain_google_genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "from openai import OpenAI\n",
        "import PyPDF2\n",
        "import re\n",
        "import langchain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from google.colab import userdata\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV\n",
        "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_tavily import TavilySearch\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "# Initialize OpenAI client\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY_1')\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get('TAVILY_KEY')\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "epVsA8nz2GBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pydantic\n",
        "import json\n",
        "import faiss\n",
        "from pydantic import BaseModel,Field\n",
        "from langchain_core.tools import tool\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "from langchain_openai  import ChatOpenAI\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_core.messages import BaseMessage\n",
        "from typing import Annotated, Any\n",
        "from typing_extensions import TypedDict\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0)\n",
        "tavily = TavilySearch(max_results=5,search_depth=\"advanced\",format=\"json\")\n",
        "\n",
        "# Set up the API wrapper\n",
        "\n",
        "import serpapi\n",
        "tools = [tavily]\n",
        "from langchain_core.messages import AIMessage,ToolMessage\n",
        "llm_with_tools=llm.bind_tools(tools=tools)\n",
        "class Researchpaper(TypedDict):\n",
        "  messages:Annotated[list,add_messages]\n",
        "  paper_content: str\n",
        "  search_results: list\n",
        "  scores: dict\n",
        "  red_result : str\n",
        "graph_builder = StateGraph(Researchpaper)\n",
        "\n",
        "def parse_scores(response: str) -> dict:\n",
        "  scores = dict(line.split(\": \") for line in response.strip().splitlines())\n",
        "  scores = {k: float(v) for k, v in scores.items()}\n",
        "  return scores\n",
        "\n",
        "def initial_analysis(paper:Researchpaper)->Researchpaper:\n",
        "  #initiate search queries\n",
        "  messages = [\n",
        "        {\"role\":\"system\", \"content\": \"\"\"Analyze the research paper and generate search queries to:\n",
        "        1. Find similar papers for methodology verification\n",
        "        2. Find cited references for fact-checking\n",
        "        3. Find competing approaches for comparison\"\"\"},\n",
        "        {\"role\" : \"user\",\"content\": paper[\"paper_content\"]}\n",
        "    ]\n",
        "  response = llm_with_tools.invoke(messages)\n",
        "  print(response)\n",
        "\n",
        "\n",
        "# Extract queries\n",
        "\n",
        "  paper[\"messages\"] = response\n",
        "\n",
        "  return paper\n",
        "\n",
        "def process_results(paper:Researchpaper)->Researchpaper:\n",
        "\n",
        "    last_tool_message = paper[\"messages\"][-1]\n",
        "    print(last_tool_message)\n",
        "\n",
        "    # Extract from ToolMessage content (not tool_calls)\n",
        "    if isinstance(last_tool_message, ToolMessage):\n",
        "        # Tavily results are already in message content\n",
        "        search_results = last_tool_message.content\n",
        "        paper[\"search_results\"] = json.loads(search_results)\n",
        "    else:\n",
        "        print(\"Unexpected message type:\", type(last_tool_message))\n",
        "    return paper\n",
        "\n",
        "\n",
        "\n",
        "def finalscore(state:Researchpaper)->Researchpaper:\n",
        "\n",
        "    analysis_prompt = [\n",
        "        {\"role\":\"system\", \"content\":f\"\"\"Analyze the paper using these steps:\n",
        "        1. Cross-verify methodology with {state[\"search_results\"] }\n",
        "        2. Check factual claims against found references\n",
        "        3. Compare results with similar papers\n",
        "        4. Score each category (0-10) with explanations\n",
        "        5. all of these parameters methodology, technical soundness, factual correctness, rigorousity, novelty, results, clarity, and ethics\n",
        "        should be on a 0â€“10 scale\n",
        "        6. total should be sum of the values of all the parameters and should be on a 0-80 scale\n",
        "        7. the score should be floating point number rounded upto two decimal places.\"\"\"},\n",
        "\n",
        "        {\"role\":\"user\", \"content\":f'''Paper content:\\n{state[\"paper_content\"]}\\n\\nReferences:\\n{state[\"search_results\"]}\n",
        "                     This is the format you must follow for scoring:\n",
        "                     methodology: X\n",
        "                     technical_soundness: X\n",
        "                     factual_correctness: X\n",
        "                     rigorousity: X\n",
        "                     novelty: X\n",
        "                     results: X\n",
        "                     clarity: X\n",
        "                     ethics: X\n",
        "                     total : X\n",
        "                     Display only the scores in this format.'''}\n",
        "    ]\n",
        "\n",
        "    response = llm.invoke(analysis_prompt)\n",
        "    print(response)\n",
        "    return {\"scores\": parse_scores(response.content)}\n",
        "graph_builder.add_node(\"analyze_paper\",initial_analysis)\n",
        "graph_builder.add_node(\"process_results\", process_results)\n",
        "graph_builder.add_node(\"tools\", ToolNode([tavily]))\n",
        "\n",
        "\n",
        "graph_builder.add_node(\"finalscore\", finalscore)\n",
        "graph_builder.set_entry_point(\"analyze_paper\")\n",
        "graph_builder.add_edge(\"analyze_paper\", \"tools\")\n",
        "graph_builder.add_edge(\"tools\", \"process_results\")\n",
        "graph_builder.add_edge(\"process_results\", \"finalscore\")\n",
        "graph_builder.add_edge(\"finalscore\", END)\n",
        "graph = graph_builder.compile()\n"
      ],
      "metadata": {
        "id": "gUVbFM3A2O9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install gdown\n",
        "!gdown --folder \"https://drive.google.com/drive/folders/1-658SR6wI7EBthpHFJDHmJ_0iyaubU-f\"\n",
        "import numpy as np\n",
        "def conference_teller(fname):\n",
        "  if(fname==\"R006.pdf\" or fname==\"R007.pdf\"):return \"CVPR\"\n",
        "  elif (fname==\"R008.pdf\"or fname==\"R009.pdf\"):return\"EMNLP\"\n",
        "  elif (fname==\"R010.pdf\"or fname==\"R011.pdf\"):return\"KDD\"\n",
        "  elif (fname==\"R012.pdf\"or fname==\"R013.pdf\"):return\"NeurIPS\"\n",
        "  else: return \"TMLR\"\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
        "all_chunks = []\n",
        "dicd = []\n",
        "for i in range(1,16):\n",
        "    docs1=\" \"\n",
        "    if(i>=1 and i<=5):\n",
        "       base_dir = \"/content/Reference/Non-Publishable\"\n",
        "    else:\n",
        "       base_dir = \"/content/Reference/Publishable\"\n",
        "    fname = f\"R{i:03}.pdf\"\n",
        "    if(i>=1 and i<=5):\n",
        "      file_path = os.path.join(base_dir,fname)\n",
        "    if(i>=6 and i<=15):\n",
        "      conference = conference_teller(fname)\n",
        "      file_path = os.path.join(base_dir, conference, fname)\n",
        "    loader = PyPDFLoader(file_path)\n",
        "    docs = loader.load()\n",
        "    for doc in docs:\n",
        "       docs1 = docs1 + doc.page_content\n",
        "       fname = f\"R{i:03}.pdf\"\n",
        "       doc.metadata[\"source_file\"] = fname\n",
        "       if(i>=6 and i<=15):\n",
        "         doc.metadata[\"conference\"] = conference_teller(fname)\n",
        "    if(i>=6 and i<=15):\n",
        "      chunks = splitter.split_documents(docs)\n",
        "      all_chunks.extend(chunks)\n",
        "    inputs = {\n",
        "    \"messages\": [],\n",
        "    \"paper_content\": docs1,\n",
        "    \"search_results\": [],\n",
        "    \"scores\": {},\n",
        "    \"red_result\": \" \"}\n",
        "    final_output = None\n",
        "\n",
        "# Run the graph step by step\n",
        "    for step in graph.stream({\n",
        "    \"messages\": [],\n",
        "    \"paper_content\": docs1,\n",
        "    \"search_results\": [],\n",
        "    \"scores\": {},\n",
        "    \"red_result\": \" \"\n",
        "}): print(step)\n",
        "\n",
        "    dicd.append(step['finalscore'][\"scores\"])\n"
      ],
      "metadata": {
        "id": "pgtFugqW2aWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array([[dic['methodology'],dic['technical_soundness'],dic['factual_correctness'],dic['rigorousity'],dic['novelty']\n",
        "                            ,dic['results'],dic['clarity'],dic['ethics'], dic['total']]   for dic in dicd])\n",
        "label = np.array([0,0,0,0,0,1,1,1,1,1,1,1,1,1,1])\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.2, random_state=42)\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "print(y_pred)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "F1_score = f1_score(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(F1_score)\n",
        "print(accuracy)\n",
        "print(cm)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "wZtMAB-e2nom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "def xml_to_readable_string(xml_data):\n",
        "    xml_data = xml_data.strip()  # Remove leading/trailing whitespace\n",
        "\n",
        "    # Handle potential Byte Order Mark (BOM) if present\n",
        "    if xml_data.startswith('\\ufeff'):\n",
        "        xml_data = xml_data[1:]\n",
        "\n",
        "    try:\n",
        "        root = ET.fromstring(xml_data)\n",
        "    except ET.ParseError as e:\n",
        "        # If basic cleaning doesn't work, try more aggressive cleaning\n",
        "        xml_data = xml_data.replace('\\n', ' ').replace('\\t', ' ').replace('\\r', ' ')\n",
        "        xml_data = ' '.join(xml_data.split())  # Collapse multiple spaces\n",
        "        root = ET.fromstring(xml_data)\n",
        "\n",
        "    # Define namespaces\n",
        "    ns = {\n",
        "        'atom': 'http://www.w3.org/2005/Atom',\n",
        "        'arxiv': 'http://arxiv.org/schemas/atom',\n",
        "        'opensearch': 'http://a9.com/-/spec/opensearch/1.1/'\n",
        "    }\n",
        "\n",
        "    # Initialize result string\n",
        "    result = []\n",
        "\n",
        "    # Add search metadata\n",
        "    result.append(\"=== ARXIV SEARCH RESULTS ===\")\n",
        "    result.append(f\"Query: {root.find('atom:title', ns).text}\")\n",
        "    result.append(f\"Total Results: {root.find('opensearch:totalResults', ns).text}\")\n",
        "    result.append(f\"Showing: {root.find('opensearch:itemsPerPage', ns).text} of {root.find('opensearch:totalResults', ns).text}\")\n",
        "    result.append(\"\\n\")\n",
        "\n",
        "    # Process each entry\n",
        "    for entry in root.findall('atom:entry', ns):\n",
        "        # Basic info\n",
        "        result.append(f\"Title: {entry.find('atom:title', ns).text.strip()}\")\n",
        "        result.append(f\"Authors: {', '.join([a.find('atom:name', ns).text for a in entry.findall('atom:author', ns)])}\")\n",
        "        result.append(f\"Published: {entry.find('atom:published', ns).text}\")\n",
        "        result.append(f\"Updated: {entry.find('atom:updated', ns).text}\")\n",
        "\n",
        "        # Links\n",
        "        pdf_link = [link.get('href') for link in entry.findall('atom:link', ns)\n",
        "                   if link.get('type') == 'application/pdf'][0]\n",
        "        result.append(f\"PDF: {pdf_link}\")\n",
        "\n",
        "        # Abstract\n",
        "        abstract = entry.find('atom:summary', ns).text.strip()\n",
        "        result.append(f\"\\nAbstract:\\n{abstract}\\n\")\n",
        "\n",
        "        # Categories\n",
        "        categories = [cat.get('term') for cat in entry.findall('atom:category', ns)]\n",
        "        result.append(f\"Categories: {', '.join(categories)}\\n\")\n",
        "\n",
        "        result.append(\"=\"*50 + \"\\n\")\n",
        "\n",
        "    return '\\n'.join(result)\n",
        "def extract_url(xmll):\n",
        "  import xml.etree.ElementTree as ET\n",
        "  feed = ET.fromstring(xmll)  # Replace xml_content with your XML string\n",
        "  # Namespace handling (required for Atom feeds)\n",
        "  ns = {'atom': 'http://www.w3.org/2005/Atom'}\n",
        "  # Extract PDF URLs\n",
        "  pdf_urls = []\n",
        "  for entry in feed.findall('atom:entry', ns):\n",
        "    for link in entry.findall('atom:link', ns):\n",
        "        if link.get('title') == 'pdf' and link.get('rel') == 'related':\n",
        "            pdf_urls.append(link.get('href'))\n",
        "  return pdf_urls\n",
        "\n",
        "def extract_rel(xmll):\n",
        "  import xml.etree.ElementTree as ET\n",
        "  # Load your XML content here\n",
        "  tree = ET.fromstring(xmll)\n",
        "  titless = []\n",
        "  abs=[]\n",
        "  cats = []\n",
        "  # Namespace for arXiv Atom feed\n",
        "  ns = {'atom': 'http://www.w3.org/2005/Atom'}\n",
        "  # Iterate through each entry in the feed\n",
        "  for entry in tree.findall('atom:entry', ns):\n",
        "    title = entry.find('atom:title', ns).text.strip()\n",
        "    abstract = entry.find('atom:summary', ns).text.strip()\n",
        "\n",
        "    # The 'category' element has an attribute 'term'\n",
        "    category_elem = entry.find('atom:category', ns)\n",
        "    category_term = category_elem.attrib['term'] if category_elem is not None else 'N/A'\n",
        "    titless.append(title)\n",
        "    abs.append(abstract)\n",
        "    cats.append(category_term)\n",
        "  return (titless,abs,cats)\n",
        "\n",
        "def clean_research_paper(text):\n",
        "\n",
        "    # Remove References (case-insensitive)\n",
        "    text = re.sub(r'(?i)\\breferences\\b.*', '', text, flags=re.DOTALL)\n",
        "\n",
        "    # Remove Appendix (case-insensitive)\n",
        "    text = re.sub(r'(?i)\\bappendix\\b.*', '', text, flags=re.DOTALL)\n",
        "\n",
        "    # Remove Conclusion (case-insensitive)\n",
        "    text = re.sub(r'(?i)\\bconclusion\\b.*', '', text, flags=re.DOTALL)\n",
        "    text = re.sub(r'(?i)\\bconclusions\\b.*', '', text, flags=re.DOTALL)\n",
        "    # Remove Acknowledgements (optional)\n",
        "    text = re.sub(r'(?i)\\backnowledgements\\b.*', '', text, flags=re.DOTALL)\n",
        "\n",
        "\n",
        "    # Remove multiple newlines and extra spaces\n",
        "    text = re.sub(r'\\n\\s*\\n', '\\n\\n', text)\n",
        "\n",
        "    return text\n",
        "\n",
        "def complete_operation(pdf_url,ctext):\n",
        "  import requests\n",
        "  from pathlib import Path\n",
        "  docs=[]\n",
        "  i = 1\n",
        "  from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "  from sklearn.metrics.pairwise import cosine_similarity\n",
        "  def preprocess(text):\n",
        "    # Lowercase + remove special chars\n",
        "      text = re.sub(r'[^a-zA-Z\\s]', '', text.lower())\n",
        "\n",
        "    # Remove stopwords\n",
        "      stop_words = set(stopwords.words('english'))\n",
        "      words = text.split()\n",
        "      words = [w for w in words if w not in stop_words]\n",
        "\n",
        "    # Lemmatization\n",
        "      lemmatizer = WordNetLemmatizer()\n",
        "      words = [lemmatizer.lemmatize(w) for w in words]\n",
        "\n",
        "      return \" \".join(words)\n",
        "\n",
        "  vectorizer = TfidfVectorizer()\n",
        "  for url in pdf_url:\n",
        "    text = \" \"\n",
        "    try:\n",
        "            response = requests.get(url)\n",
        "            response.raise_for_status()  # Raises HTTPError for bad status\n",
        "    except requests.HTTPError as e:\n",
        "            print(f\"Skipping {url}: {e}\")\n",
        "            continue # Check for HTTP errors\n",
        "    filename = Path(url).name + \".pdf\"  # e.g., \"1710.02318v1.pdf\"\n",
        "    with open(filename, \"wb\") as f:\n",
        "      f.write(response.content)\n",
        "    with open(filename, \"rb\") as f:\n",
        "      reader = PyPDF2.PdfReader(f)\n",
        "      for page in reader.pages:\n",
        "        page_text = page.extract_text()\n",
        "        if page_text:\n",
        "          # Clean the text (remove page numbers at the end)\n",
        "          page_text = re.sub(r'\\s*\\d+\\s*$', ' ', page_text)\n",
        "          text += page_text + \"\\n\"  # Add a newline between pages\n",
        "    text = clean_research_paper(text)\n",
        "    docs.append(text)\n",
        "\n",
        "  processed1 = preprocess(ctext)\n",
        "  process = []\n",
        "  for doc in docs:\n",
        "      proc = {}\n",
        "      processed2 = preprocess(doc)\n",
        "      tfidf_matrix = vectorizer.fit_transform([processed1, processed2])\n",
        "      similarity = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])[0][0]\n",
        "      print(f\"Cosine Similarity: {similarity:.2f}\")\n",
        "      proc['similarity_ score'] = similarity\n",
        "\n",
        "      process.append(proc)\n",
        "  return process\n",
        "def extract_title(text):\n",
        "    # Match text before \"Abstract\", allowing for line breaks\n",
        "    match = re.search(r'^(.*?)\\bAbstract\\b', text, re.DOTALL | re.IGNORECASE)\n",
        "    if match:\n",
        "        # Clean up: remove extra whitespace and join lines\n",
        "        title = ' '.join(match.group(1).split()).strip()\n",
        "        return title\n",
        "    return None\n",
        "def arxiv_query_url_from_title(title: str, max_results: int = 5, search_field: str = \"all\") -> str:\n",
        "  encoded_title = urllib.parse.quote_plus(title.strip())\n",
        "  base_url = \"http://export.arxiv.org/api/query\"\n",
        "  query = f\"{base_url}?search_query={search_field}:{encoded_title}&max_results={max_results}\"\n",
        "  return query"
      ],
      "metadata": {
        "id": "22gLZ4KP2xYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib, urllib.request\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "import re # Import the re module\n",
        "\n",
        "# Use your already-configured GOOGLE_API_KEY (env or secret manager)\n",
        "embedding = GoogleGenerativeAIEmbeddings(\n",
        "    model=\"models/embedding-001\",          # or \"text-embedding-004\"\n",
        "    task_type=\"RETRIEVAL_DOCUMENT\"         # or \"RETRIEVAL_QUERY\"\n",
        ")\n",
        "dim = 1536\n",
        "vectorstore = FAISS.from_documents(all_chunks, embedding,distance_strategy=\"DOT_PRODUCT\")\n",
        "vectorstore.save_local(\"/content/faiss_index\")\n",
        "vectorstore = FAISS.load_local(\"/content/faiss_index\", embedding,allow_dangerous_deserialization=True)\n",
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", k=3)\n",
        "class ResearchPaper(TypedDict):\n",
        "  messages: str\n",
        "  arxiv_results : list\n",
        "  reason: str\n",
        "  retrieved_docs: list\n",
        "  conference:str\n",
        "def retrieve_step(state):\n",
        "    query = state[\"messages\"]\n",
        "    # Clean the query string\n",
        "    query = re.sub(r'\\s+', ' ', query).strip() # Replace multiple whitespace with single space and strip\n",
        "    query = re.sub(r'[^\\x00-\\x7F]+', '', query) # Remove non-ASCII characters\n",
        "    query = clean_research_paper(query)\n",
        "    docs = retriever.invoke(query)\n",
        "    state[\"retrieved_docs\"]= docs\n",
        "    return state\n",
        "\n",
        "def result_fetching(state):\n",
        "  docs = state['messages']\n",
        "  title = extract_title(docs)\n",
        "\n",
        "  url = arxiv_query_url_from_title(title, max_results=5, search_field=\"all\")\n",
        "  data = urllib.request.urlopen(url)\n",
        "  ymll = data.read().decode('utf-8')\n",
        "\n",
        "  pdf_url = extract_url(ymll)\n",
        "  titles,abs,cats = extract_rel(ymll)\n",
        "  process = complete_operation(pdf_url,docs)\n",
        "  for proc,tit,abs,cat in zip(process,titles,abs,cats):\n",
        "    proc['title'] = tit\n",
        "    proc['abstract'] = abs\n",
        "    proc['category'] = cat\n",
        "  state[\"arxiv_results\"] = process\n",
        "  return state\n",
        "def llms(state):\n",
        "  docs = state[\"retrieved_docs\"]\n",
        "  docss = state[\"arxiv_results\"]\n",
        "  system_msg = '''from the given information  predict the conference out of TMLR,KDD,EMNLP,CVPR,NeurIPS and also give tell why this conference.\n",
        "\n",
        "                  '''\n",
        "  user_msg = f'''first analyze {docs} and then analyze {docss} and then predict the conference .\n",
        "                 display the name of the conference only.\n",
        "                  '''\n",
        "  response = llm.invoke([{\"role\": \"system\", \"content\": system_msg},\n",
        "                         {\"role\": \"user\",   \"content\": user_msg}])\n",
        "  state[\"conference\"] = response.content\n",
        "\n",
        "  return state\n",
        "graphs_builder = StateGraph(ResearchPaper)\n",
        "graphs_builder.add_node(\"retrieve_step\",retrieve_step)\n",
        "graphs_builder.set_entry_point(\"retrieve_step\")\n",
        "graphs_builder.add_node(\"llms\",llms)\n",
        "graphs_builder.add_node(\"result_fetching\",result_fetching)\n",
        "graphs_builder.add_edge(\"retrieve_step\",\"result_fetching\")\n",
        "graphs_builder.add_edge(\"result_fetching\",\"llms\")\n",
        "graphs_builder.add_edge(\"llms\", END)\n",
        "graphs = graphs_builder.compile()\n",
        "def get_reason_text(conf): # Renamed from reason\n",
        "  if(conf==\"CVPR\"):\n",
        "    dfg = '''focuses on computer vision tasks: image classification, object detection, segmentation, 3D reconstruction, video analysis, etc.\n",
        "            It proposes new vision models or datasets.It includes strong empirical results on vision benchmarks (like ImageNet, COCO, etc.).'''\n",
        "  elif(conf==\"KDD\"):\n",
        "    dfg = '''It emphasizes data mining, large-scale data analysis, or real-world data applications.\n",
        "           It often bridges theory and applied machine learning for massive datasets.\n",
        "           Strong industrial or data-driven focus is common. '''\n",
        "  elif(conf==\"TMLR\"):\n",
        "    dfg = '''It is a general machine learning paper with strong theoretical or empirical contributions.'''\n",
        "  elif(conf==\"EMNLP\"):\n",
        "    dfg = '''It focuses on natural language processing: syntax, semantics, text generation, sentiment analysis, etc.\n",
        "             It has strong empirical grounding (usually large-scale experiments on NLP tasks).\n",
        "             Often includes new datasets, benchmarks, or language models.  '''\n",
        "  else :\n",
        "    dfg = ''' It contributes to foundational machine learning, AI, or optimization.\n",
        "             It can be theoretical or applied but must show novelty and general relevance.\n",
        "              It may cross disciplines: neuroscience, cognitive science, economics, etc.  '''\n",
        "  return dfg"
      ],
      "metadata": {
        "id": "0Ra_1OPL27QR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name =[]\n",
        "conference = []\n",
        "conference_reasons = [] # Renamed from reasons\n",
        "for i in range(1,11):\n",
        "\n",
        "  docs2=\" \"\n",
        "  base_dir = \"/content\"\n",
        "  fname = f\"P{i:03}.pdf\"\n",
        "  os.path.join(base_dir, fname)\n",
        "  loader = PyPDFLoader(os.path.join(base_dir, fname))\n",
        "  docs = loader.load()\n",
        "  for doc in docs:\n",
        "       docs2 = docs2 + doc.page_content\n",
        "  for step in graph.stream({\n",
        "    \"messages\": [],\n",
        "    \"paper_content\": docs2,\n",
        "    \"search_results\": [],\n",
        "    \"scores\": {},\n",
        "    \"red_result\": \" \"\n",
        "})  :\n",
        "     print(step)\n",
        "  div = step[\"finalscore\"][\"scores\"]\n",
        "  data = np.array([div['methodology'],div['technical_soundness'],div['factual_correctness'],div['rigorousity'],div['novelty']\n",
        "                            ,div['results'],div['clarity'],div['ethics'], div['total']]   )\n",
        "  rty = rf_classifier.predict([data])\n",
        "  conference=[]\n",
        "  name=[]\n",
        "  conference_reasons=[] # Renamed from reasons\n",
        "  if(rty==0):\n",
        "\n",
        "\n",
        "         conf=\"NA\"\n",
        "\n",
        "         print(f\"{fname} belongs to {conf}\")\n",
        "  else:\n",
        "\n",
        "         dfg =  graphs.invoke( {\n",
        "           \"messages\": docs2,\n",
        "           \"arxiv_results\": [ ],\n",
        "            \"imp_points\" : \" \",\n",
        "            \"retrieved_docs\": [],\n",
        "             \"conference\":\" \"\n",
        "            } )\n",
        "\n",
        "\n",
        "         conf=dfg[\"conference\"]\n",
        "\n",
        "         conference_reasons.append(get_reason_text(conf)) # Updated function call\n",
        "         print(f\"{fname} belongs to {conf}\")\n",
        "\n",
        "for i in range(12,16):\n",
        "\n",
        "  docs2=\" \"\n",
        "  base_dir = \"/content\"\n",
        "  fname = f\"P{i:03}.pdf\"\n",
        "  os.path.join(base_dir, fname)\n",
        "  loader = PyPDFLoader(os.path.join(base_dir, fname))\n",
        "  docs = loader.load()\n",
        "  for doc in docs:\n",
        "       docs2 = docs2 + doc.page_content\n",
        "  for step in graph.stream({\n",
        "    \"messages\": [],\n",
        "    \"paper_content\": docs2,\n",
        "    \"search_results\": [],\n",
        "    \"scores\": {},\n",
        "    \"red_result\": \" \"\n",
        "})  :\n",
        "     print(step)\n",
        "  div = step[\"finalscore\"][\"scores\"]\n",
        "  data = np.array([div['methodology'],div['technical_soundness'],div['factual_correctness'],div['rigorousity'],div['novelty']\n",
        "                            ,div['results'],div['clarity'],div['ethics'], div['total']]   )\n",
        "  rty = rf_classifier.predict([data])\n",
        " # Renamed from reasons\n",
        "  if(rty==0):\n",
        "\n",
        "\n",
        "         conf=\"NA\"\n",
        "\n",
        "         print(f\"{fname} belongs to {conf}\")\n",
        "  else:\n",
        "\n",
        "         dfg =  graphs.invoke( {\n",
        "           \"messages\": docs2,\n",
        "           \"arxiv_results\": [ ],\n",
        "            \"imp_points\" : \" \",\n",
        "            \"retrieved_docs\": [],\n",
        "             \"conference\":\" \"\n",
        "            } )\n",
        "\n",
        "\n",
        "         conf=dfg[\"conference\"]\n",
        "\n",
        "         conference_reasons.append(get_reason_text(conf)) # Updated function call\n",
        "         print(f\"{fname} belongs to {conf}\")\n"
      ],
      "metadata": {
        "id": "JKZoEtw82_I_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(16,18):\n",
        "\n",
        "  docs2=\" \"\n",
        "  base_dir = \"/content\"\n",
        "  fname = f\"P{i:03}.pdf\"\n",
        "  os.path.join(base_dir, fname)\n",
        "  loader = PyPDFLoader(os.path.join(base_dir, fname))\n",
        "  docs = loader.load()\n",
        "  for doc in docs:\n",
        "       docs2 = docs2 + doc.page_content\n",
        "  for step in graph.stream({\n",
        "    \"messages\": [],\n",
        "    \"paper_content\": docs2,\n",
        "    \"search_results\": [],\n",
        "    \"scores\": {},\n",
        "    \"red_result\": \" \"\n",
        "})  :\n",
        "     print(step)\n",
        "  div = step[\"finalscore\"][\"scores\"]\n",
        "  data = np.array([div['methodology'],div['technical_soundness'],div['factual_correctness'],div['rigorousity'],div['novelty']\n",
        "                            ,div['results'],div['clarity'],div['ethics'], div['total']]   )\n",
        "  rty = rf_classifier.predict([data])\n",
        " # Renamed from reasons\n",
        "  if(rty==0):\n",
        "\n",
        "\n",
        "         conf=\"NA\"\n",
        "\n",
        "         print(f\"{fname} belongs to {conf}\")\n",
        "  else:\n",
        "\n",
        "         dfg =  graphs.invoke( {\n",
        "           \"messages\": docs2,\n",
        "           \"arxiv_results\": [ ],\n",
        "            \"imp_points\" : \" \",\n",
        "            \"retrieved_docs\": [],\n",
        "             \"conference\":\" \"\n",
        "            } )\n",
        "\n",
        "\n",
        "         conf=dfg[\"conference\"]\n",
        "\n",
        "         conference_reasons.append(get_reason_text(conf)) # Updated function call\n",
        "         print(f\"{fname} belongs to {conf}\")"
      ],
      "metadata": {
        "id": "j5sOXF4m3LV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(19,20):\n",
        "\n",
        "  docs2=\" \"\n",
        "  base_dir = \"/content\"\n",
        "  fname = f\"P{i:03}.pdf\"\n",
        "  os.path.join(base_dir, fname)\n",
        "  loader = PyPDFLoader(os.path.join(base_dir, fname))\n",
        "  docs = loader.load()\n",
        "  for doc in docs:\n",
        "       docs2 = docs2 + doc.page_content\n",
        "  for step in graph.stream({\n",
        "    \"messages\": [],\n",
        "    \"paper_content\": docs2,\n",
        "    \"search_results\": [],\n",
        "    \"scores\": {},\n",
        "    \"red_result\": \" \"\n",
        "})  :\n",
        "     print(step)\n",
        "  div = step[\"finalscore\"][\"scores\"]\n",
        "  data = np.array([div['methodology'],div['technical_soundness'],div['factual_correctness'],div['rigorousity'],div['novelty']\n",
        "                            ,div['results'],div['clarity'],div['ethics'], div['total']]   )\n",
        "  rty = rf_classifier.predict([data])\n",
        " # Renamed from reasons\n",
        "  if(rty==0):\n",
        "\n",
        "\n",
        "         conf=\"NA\"\n",
        "\n",
        "         print(f\"{fname} belongs to {conf}\")\n",
        "  else:\n",
        "\n",
        "         dfg =  graphs.invoke( {\n",
        "           \"messages\": docs2,\n",
        "           \"arxiv_results\": [ ],\n",
        "            \"imp_points\" : \" \",\n",
        "            \"retrieved_docs\": [],\n",
        "             \"conference\":\" \"\n",
        "            } )\n",
        "\n",
        "\n",
        "         conf=dfg[\"conference\"]\n",
        "\n",
        "         conference_reasons.append(get_reason_text(conf)) # Updated function call\n",
        "         print(f\"{fname} belongs to {conf}\")"
      ],
      "metadata": {
        "id": "AxQBwehP3PRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20,29):\n",
        "\n",
        "  docs2=\" \"\n",
        "  base_dir = \"/content\"\n",
        "  fname = f\"P{i:03}.pdf\"\n",
        "  os.path.join(base_dir, fname)\n",
        "  loader = PyPDFLoader(os.path.join(base_dir, fname))\n",
        "  docs = loader.load()\n",
        "  for doc in docs:\n",
        "       docs2 = docs2 + doc.page_content\n",
        "  for step in graph.stream({\n",
        "    \"messages\": [],\n",
        "    \"paper_content\": docs2,\n",
        "    \"search_results\": [],\n",
        "    \"scores\": {},\n",
        "    \"red_result\": \" \"\n",
        "})  :\n",
        "     print(step)\n",
        "  div = step[\"finalscore\"][\"scores\"]\n",
        "  data = np.array([div['methodology'],div['technical_soundness'],div['factual_correctness'],div['rigorousity'],div['novelty']\n",
        "                            ,div['results'],div['clarity'],div['ethics'], div['total']]   )\n",
        "  rty = rf_classifier.predict([data])\n",
        "  conference=[]\n",
        "  name=[]\n",
        "  conference_reasons=[] # Renamed from reasons\n",
        "  if(rty==0):\n",
        "\n",
        "         name.append(fname)\n",
        "         conf=\"NA\"\n",
        "         conference.append(conf)\n",
        "         print(f\"{fname} belongs to {conf}\")\n",
        "  else:\n",
        "\n",
        "         dfg =  graphs.invoke( {\n",
        "           \"messages\": docs2,\n",
        "           \"arxiv_results\": [ ],\n",
        "            \"imp_points\" : \" \",\n",
        "            \"retrieved_docs\": [],\n",
        "             \"conference\":\" \"\n",
        "            } )\n",
        "\n",
        "         name.append(fname)\n",
        "         conf=dfg[\"conference\"]\n",
        "         conference.append(conf)\n",
        "         conference_reasons.append(get_reason_text(conf)) # Updated function call\n",
        "         print(f\"{fname} belongs to {conf}\")"
      ],
      "metadata": {
        "id": "_uJJ5ck03TCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(30,51):\n",
        "\n",
        "  docs2=\" \"\n",
        "  base_dir = \"/content\"\n",
        "  fname = f\"P{i:03}.pdf\"\n",
        "  os.path.join(base_dir, fname)\n",
        "  loader = PyPDFLoader(os.path.join(base_dir, fname))\n",
        "  docs = loader.load()\n",
        "  for doc in docs:\n",
        "       docs2 = docs2 + doc.page_content\n",
        "  for step in graph.stream({\n",
        "    \"messages\": [],\n",
        "    \"paper_content\": docs2,\n",
        "    \"search_results\": [],\n",
        "    \"scores\": {},\n",
        "    \"red_result\": \" \"\n",
        "})  :\n",
        "     print(step)\n",
        "  div = step[\"finalscore\"][\"scores\"]\n",
        "  data = np.array([div['methodology'],div['technical_soundness'],div['factual_correctness'],div['rigorousity'],div['novelty']\n",
        "                            ,div['results'],div['clarity'],div['ethics'], div['total']]   )\n",
        "  rty = rf_classifier.predict([data])\n",
        "  conference=[]\n",
        "  name=[]\n",
        "  conference_reasons=[] # Renamed from reasons\n",
        "  if(rty==0):\n",
        "\n",
        "\n",
        "         conf=\"NA\"\n",
        "\n",
        "         print(f\"{fname} belongs to {conf}\")\n",
        "  else:\n",
        "\n",
        "         dfg =  graphs.invoke( {\n",
        "           \"messages\": docs2,\n",
        "           \"arxiv_results\": [ ],\n",
        "            \"imp_points\" : \" \",\n",
        "            \"retrieved_docs\": [],\n",
        "             \"conference\":\" \"\n",
        "            } )\n",
        "\n",
        "\n",
        "         conf=dfg[\"conference\"]\n",
        "\n",
        "         conference_reasons.append(get_reason_text(conf)) # Updated function call\n",
        "         print(f\"{fname} belongs to {conf}\")"
      ],
      "metadata": {
        "id": "IkRY9GVB3XBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(51,56):\n",
        "  if(i==60 or i==78):\n",
        "    continue\n",
        "  docs2=\" \"\n",
        "  base_dir = \"/content\"\n",
        "  fname = f\"P{i:03}.pdf\"\n",
        "  os.path.join(base_dir, fname)\n",
        "  loader = PyPDFLoader(os.path.join(base_dir, fname))\n",
        "  docs = loader.load()\n",
        "  for doc in docs:\n",
        "       docs2 = docs2 + doc.page_content\n",
        "  for step in graph.stream({\n",
        "    \"messages\": [],\n",
        "    \"paper_content\": docs2,\n",
        "    \"search_results\": [],\n",
        "    \"scores\": {},\n",
        "    \"red_result\": \" \"\n",
        "})  :\n",
        "     print(step)\n",
        "  div = step[\"finalscore\"][\"scores\"]\n",
        "  data = np.array([div['methodology'],div['technical_soundness'],div['factual_correctness'],div['rigorousity'],div['novelty']\n",
        "                            ,div['results'],div['clarity'],div['ethics'], div['total']]   )\n",
        "  rty = rf_classifier.predict([data])\n",
        " # Renamed from reasons\n",
        "  if(rty==0):\n",
        "\n",
        "\n",
        "         conf=\"NA\"\n",
        "\n",
        "         print(f\"{fname} belongs to {conf}\")\n",
        "  else:\n",
        "\n",
        "         dfg =  graphs.invoke( {\n",
        "           \"messages\": docs2,\n",
        "           \"arxiv_results\": [ ],\n",
        "            \"imp_points\" : \" \",\n",
        "            \"retrieved_docs\": [],\n",
        "             \"conference\":\" \"\n",
        "            } )\n",
        "\n",
        "\n",
        "         conf=dfg[\"conference\"]\n",
        "\n",
        "         conference_reasons.append(get_reason_text(conf)) # Updated function call\n",
        "         print(f\"{fname} belongs to {conf}\")"
      ],
      "metadata": {
        "id": "_wYBFRaG3bWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(56,91):\n",
        "  if(i==60 or i==78):\n",
        "    continue\n",
        "  docs2=\" \"\n",
        "  base_dir = \"/content\"\n",
        "  fname = f\"P{i:03}.pdf\"\n",
        "  os.path.join(base_dir, fname)\n",
        "  loader = PyPDFLoader(os.path.join(base_dir, fname))\n",
        "  docs = loader.load()\n",
        "  for doc in docs:\n",
        "       docs2 = docs2 + doc.page_content\n",
        "  for step in graph.stream({\n",
        "    \"messages\": [],\n",
        "    \"paper_content\": docs2,\n",
        "    \"search_results\": [],\n",
        "    \"scores\": {},\n",
        "    \"red_result\": \" \"\n",
        "})  :\n",
        "     print(step)\n",
        "  div = step[\"finalscore\"][\"scores\"]\n",
        "  data = np.array([div['methodology'],div['technical_soundness'],div['factual_correctness'],div['rigorousity'],div['novelty']\n",
        "                            ,div['results'],div['clarity'],div['ethics'], div['total']]   )\n",
        "  rty = rf_classifier.predict([data])\n",
        "\n",
        "  if(rty==0):\n",
        "\n",
        "\n",
        "         conf=\"NA\"\n",
        "\n",
        "         print(f\"{fname} belongs to {conf}\")\n",
        "  else:\n",
        "\n",
        "         dfg =  graphs.invoke( {\n",
        "           \"messages\": docs2,\n",
        "           \"arxiv_results\": [ ],\n",
        "            \"imp_points\" : \" \",\n",
        "            \"retrieved_docs\": [],\n",
        "             \"conference\":\" \"\n",
        "            } )\n",
        "\n",
        "\n",
        "         conf=dfg[\"conference\"]\n",
        "\n",
        "         conference_reasons.append(get_reason_text(conf)) # Updated function call\n",
        "         print(f\"{fname} belongs to {conf}\")\n",
        ""
      ],
      "metadata": {
        "id": "rdrL6w1k3ccC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(92,136):\n",
        "\n",
        "  docs2=\" \"\n",
        "  base_dir = \"/content\"\n",
        "  fname = f\"P{i:03}.pdf\"\n",
        "  os.path.join(base_dir, fname)\n",
        "  loader = PyPDFLoader(os.path.join(base_dir, fname))\n",
        "  docs = loader.load()\n",
        "  for doc in docs:\n",
        "       docs2 = docs2 + doc.page_content\n",
        "  for step in graph.stream({\n",
        "    \"messages\": [],\n",
        "    \"paper_content\": docs2,\n",
        "    \"search_results\": [],\n",
        "    \"scores\": {},\n",
        "    \"red_result\": \" \"\n",
        "})  :\n",
        "     print(step)\n",
        "  div = step[\"finalscore\"][\"scores\"]\n",
        "  data = np.array([div['methodology'],div['technical_soundness'],div['factual_correctness'],div['rigorousity'],div['novelty']\n",
        "                            ,div['results'],div['clarity'],div['ethics'], div['total']]   )\n",
        "  rty = rf_classifier.predict([data])\n",
        "\n",
        "  if(rty==0):\n",
        "\n",
        "\n",
        "         conf=\"NA\"\n",
        "\n",
        "         print(f\"{fname} belongs to {conf}\")\n",
        "  else:\n",
        "\n",
        "         dfg =  graphs.invoke( {\n",
        "           \"messages\": docs2,\n",
        "           \"arxiv_results\": [ ],\n",
        "            \"imp_points\" : \" \",\n",
        "            \"retrieved_docs\": [],\n",
        "             \"conference\":\" \"\n",
        "            } )\n",
        "\n",
        "\n",
        "         conf=dfg[\"conference\"]\n",
        "\n",
        "         conference_reasons.append(get_reason_text(conf)) # Updated function call\n",
        "         print(f\"{fname} belongs to {conf}\")"
      ],
      "metadata": {
        "id": "4e9bu9GL3ldc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in [29,60]:\n",
        "\n",
        "  docs2=\" \"\n",
        "  base_dir = \"/content\"\n",
        "  fname = f\"P{i:03}.pdf\"\n",
        "  os.path.join(base_dir, fname)\n",
        "  loader = PyPDFLoader(os.path.join(base_dir, fname))\n",
        "  docs = loader.load()\n",
        "  for doc in docs:\n",
        "       docs2 = docs2 + doc.page_content\n",
        "  for step in graph.stream({\n",
        "    \"messages\": [],\n",
        "    \"paper_content\": docs2,\n",
        "    \"search_results\": [],\n",
        "    \"scores\": {},\n",
        "    \"red_result\": \" \"\n",
        "})  :\n",
        "     print(step)\n",
        "  div = step[\"finalscore\"][\"scores\"]\n",
        "  data = np.array([div['methodology'],div['technical_soundness'],div['factual_correctness'],div['rigorousity'],div['novelty']\n",
        "                            ,div['results'],div['clarity'],div['ethics'], div['total']]   )\n",
        "  rty = rf_classifier.predict([data])\n",
        " # Renamed from reasons\n",
        "  if(rty==0):\n",
        "\n",
        "\n",
        "         conf=\"NA\"\n",
        "\n",
        "         print(f\"{fname} belongs to {conf}\")\n",
        "  else:\n",
        "\n",
        "         dfg =  graphs.invoke( {\n",
        "           \"messages\": docs2,\n",
        "           \"arxiv_results\": [ ],\n",
        "            \"imp_points\" : \" \",\n",
        "            \"retrieved_docs\": [],\n",
        "             \"conference\":\" \"\n",
        "            } )\n",
        "\n",
        "\n",
        "         conf=dfg[\"conference\"]\n",
        " # Updated function call\n",
        "         print(f\"{fname} belongs to {conf}\")"
      ],
      "metadata": {
        "id": "Sq00Dcdn3p1v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}